{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"data_Loading.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/mr7495/covid19/blob/master/data_Loading_Training_Evaluating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"V_md08dqhQ9n"},"source":["# Code on (github.com/mr7495/covid19)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6JmhSAzXPUaX","outputId":"3f620295-60b0-41c8-dafc-ecadda2e6e64"},"source":["!nvidia-smi #show the allocated GPU"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5yqhPi-FS60r"},"source":["#Connect your Google Drive \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iagyum9oC5OD","executionInfo":{"elapsed":6,"status":"ok","timestamp":1628650642845,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"6f439fac-1150-4d77-bdde-b3a4fb655b90"},"source":["cd /content/drive/MyDrive/INVESTIGACION/COURSES/UTEC/PROYECTO/COVID/CLASIFICACION/covid19"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/INVESTIGACION/COURSES/UTEC/PROYECTO/COVID/CLASIFICACION/covid19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfQ6aHH0C5TQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UAp6XlqPeou","executionInfo":{"elapsed":8652,"status":"ok","timestamp":1628648275255,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"066bc2d8-99ad-49c3-c2e0-90e5892a6459"},"source":["#upgrade and install essential libraries\n","!pip install keras --upgrade\n","!pip install zipfile36\n","!pip install pydicom"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Collecting keras\n","  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: Keras 2.4.0\n","    Uninstalling Keras-2.4.0:\n","      Successfully uninstalled Keras-2.4.0\n","Successfully installed keras-2.6.0\n","Requirement already satisfied: zipfile36 in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_8FSXzTp-Msj"},"source":["#!pip install -q tensorflow==2.1\n","#!pip install -q keras==2.3.1\n","#!pip install -q tensorflow-estimator==2.1.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQKh_OyT_Q8w","executionInfo":{"elapsed":3177,"status":"ok","timestamp":1628648278402,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"62deb57e-fbc3-4e6f-8af4-eb24c6351359"},"source":["!pip install keras==2.4.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras==2.4.0\n","  Using cached Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.13)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.5.1)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.4.1)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.1)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.17.3)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.5.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.7.4.3)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.6.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.36.2)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.5.0.dev2021032900)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.34.1)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.12.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.0) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.32.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.3.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (57.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.4.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.6.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.5.0)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","Successfully installed keras-2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zw0BhQ7nPihU"},"source":["import tensorflow.keras as keras\n","\n","import numpy as np\n","import cv2\n","import os\n","import random\n","import shutil\n","import pandas as pd\n","import csv\n","import pydicom as dicom\n","import zipfile\n","from keras import optimizers\n","from keras.models import Sequential,Model\n","from keras.layers import Dropout, Flatten, Dense,Input\n","from keras.applications.resnet_v2 import ResNet50V2\n","from keras.applications.xception import Xception\n","#from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.initializers import RandomNormal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROTH36gTQDg4"},"source":["# This is a link to kaggle dataset. If you have downloaded it already, save it as kaggle.zip in the current directory.\n","# If the link expired, get the new link from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\n","#!wget -cO - 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10338/862042/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1587124102&Signature=UbIsEpcNjy3ymL%2BCt5cNunBYytcPNlMjVW4RmBKzzuwTL%2BqGHXDzKGbFM3rsewy6nWa9GJgU5ScP%2FVPFUVJdAU3gsqw7aR6En0AqbLMjZ3JE%2BMducSHY94zyZH%2Fn6LqBOwq%2F3FQmK6OC8Ze0OW5oJyNFD7nATMQU7GxbrarIMH6F6zg%2BmL%2BZF%2B6uqlZhAwYpKKLQtzVm7Tyu04Hse0ODtfKV78U3nREvAifK9CzPTRHzAh8AxIdNunMInOn10U4bzxWN%2F5x3Cex7kP6UHsTyJX2XF98eBrQinlgBuyWLbInpQDJVVl1QGFebCa7CN6lnOO2wEeV8Xy5MN6B%2FwlZvEw%3D%3D&response-content-disposition=attachment%3B+filename%3Drsna-pneumonia-detection-challenge.zip' > kaggle.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7x0sa1zuRPI9"},"source":["#Get the zip file I have shared, that contains the covid-chestxray-dataset images until 12 April\n","# Through the link below get the shared zip file and add it to your drive:\n","# https://drive.google.com/file/d/1Bwn4vTQUUB0tHK5aHh--Rk6eOxs2jg3q/view?usp=sharing\n","\n","#archive = zipfile.ZipFile('rsna-pneumonia-detection-challenge.zip') #Extract Kaggle Dataset\n","#for file in archive.namelist():\n","#     archive.extract(file, './All')\n","\n","#archive = zipfile.ZipFile('covid-chestxray-dataset.zip') #Extract covid-chestxray-Dataset\n","#for file in archive.namelist():\n","#     archive.extract(file, './covid-chestxray-dataset')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzN_Dxg5V14k"},"source":["fold_num=1 #Select Fold Number"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jbx1ajkDWFt5"},"source":["try:\n","  os.mkdir('All/All')\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmmkBuXJ7dui","executionInfo":{"elapsed":23,"status":"ok","timestamp":1628648320085,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"bec8a428-97cc-4e2c-88a1-089a5b0240af"},"source":["!git clone https://github.com/mr7495/covid19 #connect to our repository on GitHub"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'covid19' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2OhNyJFNU_bL"},"source":["#Warning: Our prepared All.csv & train1.csv to train8.csv in each fold, are based on the covid-chestxray-dataset until 12 April.\n","#If you have used https://drive.google.com/file/d/1Bwn4vTQUUB0tHK5aHh--Rk6eOxs2jg3q/view?usp=sharing link to get the covid-chestxray-dataset.zip file(like the cells above), you can use our prepared csv files\n","#But if you want to load the updated covid-chestxray-dataset, you must make some changes to the csvfiles.\n","shutil.copy('covid19/prepared_csv_files/All.csv','All')\n","for i in range(1,9): #Load the 8 training phases csv files of the indicated fold\n","  shutil.copy('covid19/prepared_csv_files/fold{}/train{}.csv'.format(fold_num,i),'.')\n","  globals()['train{}'.format(i)]=[]\n","\n","# The code for creating All.csv and training.csv files is available on  covid19/dataset preparing.ipynb."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sBwVu4XcWJY5"},"source":["images=[]\n","for r,d,f in os.walk('All/stage_2_train_images'): #Read the name of the images in both datasets\n","  for file in f:\n","    images.append(os.path.join(r,file))\n","for r,d,f in os.walk('covid-chestxray-dataset/images'):\n","  for file in f:\n","   images.append(os.path.join(r,file))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5V6MqMs7ZCK","executionInfo":{"elapsed":6,"status":"ok","timestamp":1628650666126,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"54122d3c-b8ed-4ccc-a3b1-dc56dacfd939"},"source":["print(len(images))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ZhEhGEr9kb1"},"source":["from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bi89iwNWWcR","executionInfo":{"elapsed":265557,"status":"ok","timestamp":1627312327204,"user":{"displayName":"Cristian Lazo Quispe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEhMyu5X1p3Z0TTyLkShOyBlRY120lsjYTlgTnNg=s64","userId":"12741362975872074849"},"user_tz":300},"outputId":"69404665-a896-4700-8a1d-022070b4ef3a"},"source":["'''\n","csv_all=pd.read_csv('All/All.csv', nrows=None) #Read the CSV file that contains the names of the images with their labels.\n","for index, row in tqdm(csv_all.iterrows()): #This loop reads the images, converts them to suitable format and saves them in the All directory\n","  if index<14973:\n","    continue\n","  if '.png' in row['filename']: #For creating the All.csv we have converted the kaggle dataset images to png format,\n","                                #but some of the images in the other dataset also are in the format of png, so we use try/except here to distinguish which dataset, the annotation in the CSV file belongs to.\n","    try:\n","      png_index=row['filename'].find('.png')\n","      last_name=row['filename'][:png_index]+'.dcm'\n","      ds = dicom.dcmread(os.path.join('All/stage_2_train_images',last_name))\n","      pixel_array_numpy = ds.pixel_array\n","      imgname = last_name[:-4]+'.png'\n","      cv2.imwrite(os.path.join('All/All', imgname), pixel_array_numpy)\n","    except:\n","      try:\n","        png_index=row['filename'].find('.png')\n","        img=cv2.imread(os.path.join('covid-chestxray-dataset/images',row['filename'][:png_index+4])) \n","        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","        cv2.imwrite(os.path.join('All/All', row['filename'][:png_index+4]), gray)  \n","      except:\n","        None\n","  else:\n","    img=cv2.imread(os.path.join('covid-chestxray-dataset/images',row['filename']))\n","    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    cv2.imwrite(os.path.join('All/All', row['filename']), gray)  \n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15085it [04:24, 56.94it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oclovHgs6w-x"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFNnawesW_b4"},"source":["All=[] #Thie list that is readed from All.csv\n","all_train=[] #This list contains the training annotations\n","all_test=[]\n","with open('All/All.csv',newline='', mode='r') as csvfile: #Adding All.csv rows to All list\n","      csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","      for row in csvreader:\n","          All.append(row)\n","for i in range(1,9): #Adding training1.csv to training8.csv rows to All_train list. This 1 to 8 indicate the 8 training phases\n","  with open('train{}.csv'.format(i),newline='', mode='r') as csvfile:\n","      csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","      for row in csvreader:\n","        all_train.append(row)\n","with open('all_test.csv'.format(i),newline='', mode='w') as csvfile: #Add all the other images that do not belong to the training phases, to the test set\n","    csvwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    csvwriter.writerow(['filename','class'])\n","    for row in All:\n","      if row not in all_train:\n","        csvwriter.writerow(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"teujwlOSZ1rL"},"source":["#Because we have written our code somehow to only save the epochs with the best validation accuracy during the training,\n","# we created the s_test.csv with 631 images. That is why validating each epoch for 11302 images during training would be terribly time-consuming\n","#so we select a random s_test.csv for evaluating the network during the training process."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mczHOfijXJDA"},"source":["for i in range(10): #Shuffle the All list\n","  random.shuffle(All)\n","with open('s_test.csv'.format(i),newline='', mode='w') as csvfile: #Create s_test.csv file for evaluating the network during training\n","    csvwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    csvwriter.writerow(['filename','class'])\n","    ln=0\n","    lp=0\n","    for row in All:\n","      if row not in all_train:\n","        if row[1]=='COVID-19':\n","          csvwriter.writerow(row)\n","        elif row[1]=='normal':\n","          if ln<300:\n","            csvwriter.writerow(row)\n","            ln+=1\n","        else:\n","          if lp<300:\n","            csvwriter.writerow(row)\n","            lp+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpoYfpASW-m8"},"source":["#remove the unnecessary file to increase the free space\n","try:\n","  #os.remove('kaggle.zip')\n","  shutil.rmtree('All/stage_2_train_images')\n","  shutil.rmtree('All/stage_2_test_images')\n","  shutil.rmtree('covid-chestxray-dataset')\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AgTcOGeQXrt"},"source":[""],"execution_count":null,"outputs":[]}]}