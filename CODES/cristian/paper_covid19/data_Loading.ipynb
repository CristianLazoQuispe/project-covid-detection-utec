{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yqhPi-FS60r"
   },
   "outputs": [],
   "source": [
    "#Connect your Google Drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UAp6XlqPeou"
   },
   "outputs": [],
   "source": [
    "#upgrade and install essential libraries\n",
    "!pip install keras --upgrade\n",
    "!pip install zipfile36\n",
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zw0BhQ7nPihU",
    "outputId": "7646ecb8-bfc0-4960-f4e6-d67966192ad1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pydicom as dicom\n",
    "import zipfile\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dropout, Flatten, Dense,Input\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7x0sa1zuRPI9"
   },
   "outputs": [],
   "source": [
    "#Get the zip file I have shared, that contains the covid-chestxray-dataset images until 12 April\n",
    "# Through the link below get the shared zip file and add it to your drive:\n",
    "# https://drive.google.com/file/d/1Bwn4vTQUUB0tHK5aHh--Rk6eOxs2jg3q/view?usp=sharing\n",
    "archive = zipfile.ZipFile('kaggle.zip') #Extract Kaggle Dataset\n",
    "for file in archive.namelist():\n",
    "     archive.extract(file, './All')\n",
    "archive = zipfile.ZipFile('covid-chestxray-dataset.zip') #Extract covid-chestxray-Dataset\n",
    "for file in archive.namelist():\n",
    "     archive.extract(file, './covid-chestxray-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzN_Dxg5V14k"
   },
   "outputs": [],
   "source": [
    "fold_num=1 #Select Fold Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jbx1ajkDWFt5"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  os.mkdir('All/All')\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmmkBuXJ7dui"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mr7495/covid19 #connect to our repository on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OhNyJFNU_bL"
   },
   "outputs": [],
   "source": [
    "#Warning: Our prepared All.csv & train1.csv to train8.csv in each fold, are based on the covid-chestxray-dataset until 12 April.\n",
    "#If you have used https://drive.google.com/file/d/1Bwn4vTQUUB0tHK5aHh--Rk6eOxs2jg3q/view?usp=sharing link to get the covid-chestxray-dataset.zip file(like the cells above), you can use our prepared csv files\n",
    "#But if you want to load the updated covid-chestxray-dataset, you must make some changes to the csvfiles.\n",
    "shutil.copy('covid19/prepared_csv_files/All.csv','All')\n",
    "for i in range(1,9): #Load the 8 training phases csv files of the indicated fold\n",
    "  shutil.copy('covid19/prepared_csv_files/fold{}/train{}.csv'.format(fold_num,i),'.')\n",
    "  globals()['train{}'.format(i)]=[]\n",
    "\n",
    "# The code for creating All.csv and training.csv files is available on  covid19/dataset preparing.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBwVu4XcWJY5"
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "for r,d,f in os.walk('All/stage_2_train_images'): #Read the name of the images in both datasets\n",
    "  for file in f:\n",
    "    images.append(os.path.join(r,file))\n",
    "for r,d,f in os.walk('covid-chestxray-dataset/images'):\n",
    "  for file in f:\n",
    "   images.append(os.path.join(r,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bi89iwNWWcR"
   },
   "outputs": [],
   "source": [
    "csv_all=pd.read_csv('All/All.csv', nrows=None) #Read the CSV file that contains the names of the images with their labels.\n",
    "for index, row in csv_all.iterrows(): #This loop reads the images, converts them to suitable format and saves them in the All directory\n",
    "  if '.png' in row['filename']: #For creating the All.csv we have converted the kaggle dataset images to png format,\n",
    "                                #but some of the images in the other dataset also are in the format of png, so we use try/except here to distinguish which dataset, the annotation in the CSV file belongs to.\n",
    "    try:\n",
    "      png_index=row['filename'].find('.png')\n",
    "      last_name=row['filename'][:png_index]+'.dcm'\n",
    "      ds = dicom.dcmread(os.path.join('All/stage_2_train_images',last_name))\n",
    "      pixel_array_numpy = ds.pixel_array\n",
    "      imgname = last_name[:-4]+'.png'\n",
    "      cv2.imwrite(os.path.join('All/All', imgname), pixel_array_numpy)\n",
    "    except:\n",
    "      png_index=row['filename'].find('.png')\n",
    "      img=cv2.imread(os.path.join('covid-chestxray-dataset/images',row['filename'][:png_index+4])) \n",
    "      gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "      cv2.imwrite(os.path.join('All/All', row['filename'][:png_index+4]), gray)  \n",
    "  else:\n",
    "    img=cv2.imread(os.path.join('covid-chestxray-dataset/images',row['filename']))\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(os.path.join('All/All', row['filename']), gray)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFNnawesW_b4"
   },
   "outputs": [],
   "source": [
    "All=[] #Thie list that is readed from All.csv\n",
    "all_train=[] #This list contains the training annotations\n",
    "all_test=[]\n",
    "with open('All/All.csv',newline='', mode='r') as csvfile: #Adding All.csv rows to All list\n",
    "      csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "      for row in csvreader:\n",
    "          All.append(row)\n",
    "for i in range(1,9): #Adding training1.csv to training8.csv rows to All_train list. This 1 to 8 indicate the 8 training phases\n",
    "  with open('train{}.csv'.format(i),newline='', mode='r') as csvfile:\n",
    "      csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "      for row in csvreader:\n",
    "        all_train.append(row)\n",
    "with open('all_test.csv'.format(i),newline='', mode='w') as csvfile: #Add all the other images that do not belong to the training phases, to the test set\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csvwriter.writerow(['filename','class'])\n",
    "    for row in All:\n",
    "      if row not in all_train:\n",
    "        csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teujwlOSZ1rL"
   },
   "outputs": [],
   "source": [
    "#Because we have written our code somehow to only save the epochs with the best validation accuracy during the training,\n",
    "# we created the s_test.csv with 631 images. That is why validating each epoch for 11302 images during training would be terribly time-consuming\n",
    "#so we select a random s_test.csv for evaluating the network during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mczHOfijXJDA"
   },
   "outputs": [],
   "source": [
    "for i in range(10): #Shuffle the All list\n",
    "  random.shuffle(All)\n",
    "with open('s_test.csv'.format(i),newline='', mode='w') as csvfile: #Create s_test.csv file for evaluating the network during training\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csvwriter.writerow(['filename','class'])\n",
    "    ln=0\n",
    "    lp=0\n",
    "    for row in All:\n",
    "      if row not in all_train:\n",
    "        if row[1]=='COVID-19':\n",
    "          csvwriter.writerow(row)\n",
    "        elif row[1]=='normal':\n",
    "          if ln<300:\n",
    "            csvwriter.writerow(row)\n",
    "            ln+=1\n",
    "        else:\n",
    "          if lp<300:\n",
    "            csvwriter.writerow(row)\n",
    "            lp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpoYfpASW-m8"
   },
   "outputs": [],
   "source": [
    "#remove the unnecessary file to increase the free space\n",
    "try:\n",
    "  os.remove('kaggle.zip')\n",
    "  shutil.rmtree('All/stage_2_train_images')\n",
    "  shutil.rmtree('All/stage_2_test_images')\n",
    "  shutil.rmtree('covid-chestxray-dataset')\n",
    "except:\n",
    "  pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPbe4vW4hpq36DBFkW3ZrNb",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "data Loading-Training-Evaluating.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
